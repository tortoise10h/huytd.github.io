<html>
    <head>
        <title> Nhận diện khung truyện manga với OpenCV | Huy's Blog</title>
        <meta charset="utf-8">
        <meta http-equiv="content-type" content="text/html;"><meta name=viewport content="initial-scale=1.0 maximum-scale=1.0">
        
        <link href="../css/inconsolata.css" rel="stylesheet" type="text/css">
        <link href="../css/theme.css" rel="stylesheet" type="text/css">
        <link rel="stylesheet" href="../css/highlight/tomorrow.css">
        <link rel="stylesheet" href="../css/fontello.css">
        <script src="../js/highlight.pack.js"></script>
        <script src="../js/autosizing.js"></script>
        <script>
        hljs.initHighlightingOnLoad();
        </script>
    </head>
    <body>
        <div class="header">
            <a href="/"><i class="icon icon-emo-coffee"></i> Huy's Blog</a>
        </div>
        <div class="container">
            <div class="main">
                <h1 id="nh-n-di-n-khung-truy-n-manga-v-i-opencv">Nhận diện khung truyện manga với OpenCV</h1>
<p>Đọc manga trên mobile là một nhu cầu rất lớn, nhưng hiện nay chưa có nhiều ứng dụng đáp ứng được nhu cầu này một cách hiệu quả.</p>
<h2 id="v-n-">Vấn đề</h2>
<p>Một trong những vấn đề lớn nhất của việc đọc manga trên các thiết bị mobile màn hình nhỏ (điện thoại, máy đọc sách,...) là kích thước của một trang truyện thường khá lớn, và màn hình thì rất nhỏ nên dẫn đến nhiều bất tiện khi đọc. Nhất là khi sử dụng điện thoại trong portrait mode (chiều dọc), vì lúc này chữ trong các khung truyện rất nhỏ, dẫn đến hoàn toàn không đọc được.</p>
<p><img src="img/manga-issue.png" alt=""></p>
<p>Giải pháp mà đa số các app sử dụng lúc này là đọc truyện trong landscape mode (nằm ngang), điều này tạm giải quyết được vấn đề kích thước, tuy nhiên một khung truyện vẫn rất nhỏ để đọc. Chỉ có một cách là người dùng phải tự tay zoom đến từng ô truyện nếu muốn đọc thoải mái, rất phiền phức. Thêm nữa, việc sử dụng điện thoại khi đọc truyện trong landscape mode trong thời gian dài cũng không phải là một ý kiến hay cho lắm.</p>
<p>Trên các máy đọc sách như Kindle Paperwhite, thì Amazon giải quyết bằng một cách khác, đó là cho phép user thực hiện double tap để zoom to từng góc của một trang truyện, tap thêm một cái thì sẽ dịch chuyển khung màn hình sang một góc khác, cứ như thế đi đến 4 góc của màn hình. </p>
<p><img src="img/manga-issue-kindle.png" alt=""></p>
<p>Và với cách này thì các vùng hiển thị sẽ bị chồng chéo, giống như hình trên, khi Kindle hiển thị vùng số 2, một phần nội dung của vùng số 1 vẫn bị dính vào khung hình. Không đem lại cảm giác đọc truyện thoải mái cho người dùng.</p>
<h2 id="gi-i-ph-p">Giải pháp</h2>
<p>Chắc sẽ có rất nhiều giải pháp để giải quyết vấn đề này, trong bài này mình chỉ trình bày giải pháp do mình đề xuất, đó là <strong>tách từng khung truyện ra để hiển thị độc lập trên màn hình</strong>.</p>
<p><img src="img/manga-idea.png" alt=""></p>
<p>Như hình minh họa trên, chúng ta sẽ dùng một cách nào đó (sẽ nói ở phần tiếp theo của bài viết) để phân tách một trang truyện thành từng khung nhỏ, và hiển thị độc lập từng khung (hoặc có thể hiển thị toàn trang nhưng focus vào trung tâm của từng khung truyện), mang lại trải nghiệm đọc tốt hơn cho người dùng. </p>
<p>Về ý tưởng thì hoàn toàn hợp lý và không có gì phức tạp cho lắm, nếu các khung truyện chỉ đơn giản là các hình chữ nhật, thì việc tìm và bóc tách khung truyện cũng sẽ rất dễ dàng. Tuy nhiên đa số các manga hiện nay đều sử dụng rất ít bố cục lưới hình chữ nhật ngay ngắn, mà một khung truyện thường sẽ đa dạng như hình minh họa ở trên.</p>
<p>Bài viết này sẽ trình bày về cách implement thuật toán nhận diện khung truyện sử dụng OpenCV, có thể làm việc được với các hình khối của từng khung truyện đa dạng như trên.</p>
<h2 id="implementation">Implementation</h2>
<p>Sở dĩ chọn OpenCV là vì nó cung cấp cho chúng ta rất nhiều hàm/thuật toán xử lý hình ảnh cơ bản, và ở giai đoạn này chúng ta chỉ prototype thuật toán nhận diện, chưa đi sâu vào việc implement nó vào một ứng dụng thực tế nào, nên có thể sử dụng nó thoải mái. Khi đã hình thành được phương pháp giải quyết thì chúng ta có thể tự implement toàn bộ các thuật toán liên quan nếu thích.</p>
<h3 id="load-trang-truy-n-v-o-opencv">Load trang truyện vào OpenCV</h3>
<p>Việc đầu tiên cần làm đó là load trang truyện cần xử lý vào OpenCV, ở đây chúng ta sử dụng Python và thư viện OpenCV 2.</p>
<p>Giả sử chúng ta đã có file <code>manga.jpg</code> nằm cùng thư mục với chương trình Python:</p>
<pre><code>import cv2
import numpy as np

img = cv2.imread(&#39;manga.jpg&#39;)

print img.shape
</code></pre><p>Chúng ta sử dụng hàm <code>cv2.imread</code> để đọc file hình ảnh, đối tượng <code>img</code> bây giờ sẽ là một mảng các pixel màu theo định dạng <strong>BGR</strong> (blue, green, red). Thuộc tính <code>shape</code> của <code>img</code> trả về một tuple gồm các thông tin về kích thước (số dòng, số cột) của mảng pixel, và số channel (kênh màu) trong hình đó.</p>
<p>Ở ví dụ trên, kết quả trả về sẽ là:</p>
<pre><code>(1150, 802, 3)
</code></pre><p>Tức là hình ảnh có chiều dài 1150 pixel, rộng 802 pixel và  có 3 kênh màu.</p>
<p>Mặc dù trang truyện trên là trắng đen, nhưng màu sắc mặc định của một hình ảnh sẽ có 3 kênh, quá nhiều kênh màu cũng sẽ gây cản trở cho việc xử lý vì thế chúng ta có thể convert hình ảnh trên về định dạng trắng đen (grayscale) thực sự:</p>
<pre><code>img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

print img.shape
</code></pre><p>Lúc này output sẽ chỉ còn:</p>
<pre><code>(1150, 802)
</code></pre><p>Vì là ảnh grayscale nên số channel không được hiển thị.</p>
<p>Để hiển thị hình ảnh vừa load lên màn hình, có thể sử dụng thư viện <code>matplotlib</code> như sau:</p>
<pre><code>import cv2
import numpy as np
from matplotlib import pyplot as plt

img = cv2.imread(&#39;manga.jpg&#39;)

plt.subplot(111), plt.imshow(img)
plt.show()
</code></pre><p>Hình ảnh sẽ được hiện lên qua một cửa sổ mới như sau:</p>
<p><img src="img/manga-plt-show.png" alt=""></p>
<p>Tiếp theo chúng ta sẽ thử qua một vài phép xử lý ảnh đơn giản.</p>
<h3 id="thresholding">Thresholding</h3>
<p>Một phương pháp xử lý ảnh đơn giản đó là thresholding, đây là thuật toán dùng để lọc từng pixel của một hình ảnh đen trắng theo một ngưỡng nào đó, nếu pixel đang xét có giá trị thấp hơn ngưỡng đã chỉ định, nó sẽ gán pixel đó thành một màu, nếu pixel đó có giá trị lớn hơn ngưỡng đã chỉ định, nó sẽ gán pixel đó về một màu khác.</p>
<p>Chúng ta có thể sử dụng thresholding để lọc bớt các chi tiết màu xám trong trang truyện để nó hoàn toàn trở về 2 màu đen và trắng. Như vậy ở bước nhận diện khung truyện chúng ta sẽ có kết quả chính xác hơn.</p>
<p><img src="img/manga-threshold.png" alt=""></p>
<p>Việc thresholding được thực hiện thông qua hàm <strong>cv2.threshold</strong>, hàm này có dạng:</p>
<pre><code>ret, thresh = cv2.threshold(img, &lt;classify value&gt;, &lt;max value&gt;, &lt;type&gt;)
</code></pre><p>Tham số đầu tiên là đối tượng <code>img</code>, tức là hình ảnh đầu vào cần xử lý, tham số thứ 2 <code>classify value</code> là giá trị màu trong khoảng từ <strong>$0 \rightarrow 255$</strong> (đen đến trắng) dùng làm ngưỡng phân biệt, tham số thứ 3 là giá trị sẽ được gán cho pixel đang xét nếu nó lớn hơn giá trị classify, ở đây chúng ta có thể dùng <strong>255</strong> tức là màu trắng. Cuối cùng là tham số type, nhận vào một trong các giá trị:</p>
<ul>
<li>cv2.THRESH_BINARY</li>
<li>cv2.THRESH_BINARY_INV</li>
<li>cv2.THRESH_TRUNC</li>
<li>cv2.THRESH_TOZERO</li>
<li>cv2.THRESH_TOZERO_INV</li>
</ul>
<p><img src="img/manga-thresh-types.jpg" alt=""></p>
<p>Chúng ta sẽ thử apply thuật toán thresholding với tham số <code>THRESH_BINARY</code> và xem kết quả:</p>
<pre><code>import cv2
import numpy as np
from matplotlib import pyplot as plt

img = cv2.imread(&#39;manga.jpg&#39;)
img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
ret,thresh = cv2.threshold(img, 90, 255, cv2.THRESH_BINARY)

plt.subplot(121), plt.imshow(img, cmap=&#39;Greys_r&#39;)
plt.subplot(122), plt.imshow(thresh, cmap=&#39;Greys_r&#39;)
plt.show()
</code></pre><p>Chạy thử sẽ thấy các chi tiết màu xám (như phần lửa ở khung truyện giữa) đã bị lọc bỏ:</p>
<p><img src="img/manga-thresh-binary.png" alt=""></p>
<p>Tuy nhiên các thành phần như watermark vẫn còn, để lấy khung hình chính xác hơn, chúng ta có thể tạm thời loại bỏ chúng ra khỏi vùng xác định (tất nhiên chúng ta sẽ không thay đổi bất kì nội dung nào của trang truyện khi implement trên ứng dụng thực tế cả)</p>
<p>Đồng thời, để phục vụ cho bước tiếp theo, chúng ta cũng sẽ thay giá trị <code>cv2.THRESH_BINARY</code> thành <code>cv2.THRESH_BINARY_INV</code> để đảo ngược màu sắc trong khung truyện, lý do sẽ giải thích ở bước tiếp theo.</p>
<pre><code>ret,thresh = cv2.threshold(img, 80, 255, cv2.THRESH_BINARY_INV)
</code></pre><p>Hạ giá trị ngưỡng màu xuống một tí để lọc các phần màu sáng hơn, kết quả có vẻ khả quan hơn:</p>
<p><img src="img/manga-thresh-binary-optimized.png" alt=""></p>
<h3 id="x-c-nh-contours">Xác định Contours</h3>
<p>Contours là đường bao kết nối tất cả các điểm liền kề nhau có cùng màu sắc hoặc độ tương phản. Chính vì đặc tính này, contours thường được dùng trong xác định vật thể, nhận dạng,... </p>
<p>Trong trường hợp này chúng ta cũng sẽ dùng thuật toán xác định contours làm nền tảng để xác định các khung truyện.</p>
<p>Trong OpenCV, thuật toán tìm contours hoạt động dựa trên các chi tiết có màu trắng, trên nền màu đen. Chính vì vậy ở phần trước, khi thực hiện thresholding, chúng ta đã đảo màu nền và màu nét của trang truyện.</p>
<p>Chúng ta sẽ dùng hàm <strong>cv2.findContours()</strong> để tìm hết tất cả contours trong hình, và dùng hàm <strong>cv2.drawContours()</strong> để vẽ các contours tìm được lên hình. Chi tiết về 2 hàm này các bạn có thể xem tại <a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contours_begin/py_contours_begin.html#contours-getting-started">đây</a>.</p>
<pre><code>import cv2
import numpy as np
from matplotlib import pyplot as plt

orig = cv2.imread(&#39;manga.jpg&#39;)
img = cv2.imread(&#39;manga.jpg&#39;)
result = cv2.imread(&#39;manga.jpg&#39;)
img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

ret,thresh = cv2.threshold(img, 80, 255, cv2.THRESH_BINARY_INV)
contours, h = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

for cnt in contours:
    cv2.drawContours(result, [cnt], -1, 255, -1)

plt.subplot(121), plt.imshow(orig)
plt.subplot(122), plt.imshow(result)
plt.show()
</code></pre><p>Phần màu đỏ chính là phần contours tìm được sau khi sử dụng thuật toán findContours. Ở đây mình dùng hàm <strong>drawContours</strong> để vẽ đè phần contours lên trên hình gốc để dễ hình dung:</p>
<p><img src="img/manga-contours.png" alt=""></p>
<p>Tuy nhiên, với các contours như trên, chúng ta vẫn rất khó để phân biệt được đâu là khung truyện chính xác, cần có một phương pháp hiệu quả hơn.</p>
<h3 id="convex-hull">Convex Hull</h3>
<p>Convex Hull là một đường xấp xỉ bao quanh contours, và có ít đỉnh hơn, tạo ra một hình khối tổng quát của contour đó.</p>
<p><img src="img/manga-convex-hull.jpg" alt=""></p>
<p>Ta sẽ áp dụng convex hull để xác định các đường bao quanh các contours trong một khung truyện, bằng cách này ta có thể xác định được chính xác hơn.</p>
<p>Để tìm convex hull của một contour, chúng ta sử dụng hàm <strong>cv2.convexHull()</strong>, chi tiết về hàm này có thể xem tại <a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.html?highlight=convex%20hull">đây</a>.</p>
<pre><code>for cnt in contours:
    hull = cv2.convexHull(cnt)
    cv2.drawContours(result, [cnt], -1, 255, -1)
    cv2.drawContours(result, [hull], -1, 255, -1)
</code></pre><p>Kết quả là chúng ta đã xác định được một cách tương đối chính xác từng ô truyện như hình sau:</p>
<p><img src="img/manga-convex-hull-detect.png" alt=""></p>
<p>Một số ô truyện vẫn còn bị cắt vào phần nội dung, lý do là chúng ta chưa xác định rõ phần viền của nội dung một trang truyện, và bị cắt xén trong quá trình thresholding. Vấn đề này sẽ được nói chi tiết hơn ở các bài sau.</p>
<p>Các bạn có thể tham khảo mã nguồn đầy đủ tại đây:</p>
<pre><code>import cv2
import numpy as np
from matplotlib import pyplot as plt

filename = &#39;manga.jpg&#39;

orig = cv2.imread(filename)
img = cv2.imread(filename)
result = cv2.imread(filename)
img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

ret,thresh = cv2.threshold(img, 80, 255, cv2.THRESH_BINARY_INV)

contours, h = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

for cnt in contours:
    hull = cv2.convexHull(cnt)
    cv2.drawContours(result, [cnt], -1, 255, -1)
    cv2.drawContours(result, [hull], -1, 255, -1)

plt.subplot(121), plt.imshow(orig)
plt.subplot(122), plt.imshow(result)
plt.show()
</code></pre><h2 id="th-nghi-m">Thử nghiệm</h2>
<p>Đối với các trang truyện có khung hình đã được canh chỉnh cách xa đường viền của trang, thì thuật toán hoạt động rất hiệu quả:</p>
<p><img src="img/manga-test-1.png" alt=""></p>
<p><img src="img/manga-test-2.png" alt=""></p>
<p>Đối với các truyện có nội dung tràn lề, thuật toán bắt đầu hoạt động kém hiệu quả:</p>
<p><img src="img/manga-test-fail-1.png" alt=""></p>
<p>Đặc biệt đối với những truyện có layout hoàn toàn bất thường như 2 ví dụ dưới đây thì thuật toán gần như không hoạt động 😭</p>
<p><img src="img/manga-test-fail-2.png" alt=""></p>
<p><img src="img/manga-test-fail-3.png" alt=""></p>
<h2 id="k-t-lu-n">Kết luận</h2>
<p>Tạm thời chúng ta đã thu được kết quả nhất định, thuật toán hoạt động ổn trong một số trường hợp, tuy nhiên với óc sáng tạo của các mangaka, việc bố trí layout cho một trang truyện có thể biến đổi khôn lường, đến lúc này thì thuật toán của chúng ta cần phải có cách giải quyết hiệu quả hơn.</p>
<p>Ngoài 2 trường hợp đặc biệt cuối cùng, thuật toán cần cải thiện việc xử lý khung viền đối với những trang truyện có nội dung tràn lề (như ví dụ 3), ở bài viết tới, chúng ta sẽ cùng tìm hiểu về cách tự động vẽ lại nội dung đường viền để khắc phục tình trạng này.</p>
<hr>
<p>Dữ liệu cho các ví dụ minh hoạt thuật toán ở trong bài viết được lấy từ các manga <strong>One Piece</strong> chapter 846 và <strong>GTO: Paradise Lost</strong> chap 42 từ trang <a href="http://truyentranhtuan.com">TruyenTranhTuan</a>. Việc sử dụng chỉ nhằm mục đích nghiên cứu khoa học, không hề có sự đồng thuận từ phía các tác giả Eiichiro Oda, Fujisawa Tooru hay từ phía các nhà xuất bản.</p>
<hr>
<p><img src="https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png" alt=""></p>
<div class="copyright" style="text-align: center">Bài viết được phát hành với giấy phép <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a><br/>Có thể trích dẫn nguyên văn hoặc share lại với điều kiện không được sửa đổi bất kì nội dung nào, và không được sử dụng với mục đích thương mại.</div>

<div class='other-tags'><b>Tags:</b> <a class='topic-tag' href='https://huytd.github.io/tags/algorithm.html'>algorithm</a><a class='topic-tag' href='https://huytd.github.io/tags/opencv.html'>opencv</a><a class='topic-tag' href='https://huytd.github.io/tags/hacking.html'>hacking</a><a class='topic-tag' href='https://huytd.github.io/tags/research.html'>research</a></div>
                <div class="copyright">
                Bạn được tùy ý bấm like, trích dẫn hoặc copy, post lại, nhưng vui lòng ghi rõ nguồn và tác giả và không làm thay đổi nội dung bài viết. Nếu không làm vậy, mình hy vọng từ nay về sau bạn sẽ luôn cảm thấy cắn rứt lương tâm, ăn không ngon, ngủ không yên. 😆
                </div>
                <!-- Comment -->
                <div class="comments">
                  <div id="comment-loading" class="loading"></div>
                  <div id="login-box" class="login">
                    Bạn cần <button onclick="login()">Login</button> để comment
                  </div>
                  <div id="comment-box" class="comment-input">
                    <div class="avatar">
                      <img id="user-avatar" src="" width="32" height="32"/>
                    </div>
                    <div class="input">
                      <textarea id="comment-content" onkeyup="autoSizing(this)" onkeydown="submitComment(event)" placeholder="Comment gõ vào đây :D"></textarea>
                      <span>Gõ xong nhấn <kbd>Ctrl</kbd> + <kbd>Enter</kbd> để gửi.</span>
                    </div>
                  </div>
                  <ul id="comment-list" class="comment-list"></ul>
                </div>
                <!-- End Comment -->
            </div>
        </div>
	    <div class="footer">
            <p>Created with <a href="http://github.com/huytd/azeroth-js">azeroth.js</a></p>
            <div class="social">
                <a target="_blank" href="http://facebook.com/kingbazoka"><i class="icon-facebook-squared"></i></a>
                <a target="_blank" href="http://twitter.com/huydotnet"><i class="icon-twitter-squared"></i></a>
                <a target="_blank" href="http://github.com/huytd"><i class="icon-github-squared"></i></a>
                <a target="_blank" href="https://thefullsnack.com"><i class="icon-emo-coffee"></i></a>
            </div>
        </div>
        <script type="text/javascript" async src="https://cdn.rawgit.com/mathjax/MathJax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            skipTags: ["script","noscript","style","textarea"]
          }
        });
        </script>
        <script src="https://www.gstatic.com/firebasejs/3.8.0/firebase.js"></script>
        <script>
          // Initialize Firebase
          var config = {
            apiKey: "AIzaSyA1PnIAlJJ-U6iQJMNnCOknBuziBqGMYcY",
            authDomain: "huys-blog-comment.firebaseapp.com",
            databaseURL: "https://huys-blog-comment.firebaseio.com",
            projectId: "huys-blog-comment",
            storageBucket: "huys-blog-comment.appspot.com",
            messagingSenderId: "317330376829"
          };
          firebase.initializeApp(config);
        </script>
        <script>
          let provider = new firebase.auth.GoogleAuthProvider();
          let auth = firebase.auth();
          let currentUser = null;
          let postCommentURL = 'posts/manga-frame/comments';

          auth.onAuthStateChanged(function(user) {
            document.getElementById("comment-loading").style.display = "none";
            if (user) {
              currentUser = user;
              // Logged in
              document.getElementById("login-box").style.display = "none";
              document.getElementById("comment-box").style.display = "flex";
              document.getElementById("user-avatar").setAttribute("src", user.photoURL);
            } else {
              // Not login yet
              document.getElementById("comment-box").style.display = "none";
              document.getElementById("login-box").style.display = "block";
            }
          });

          const login = function() {
            auth.signInWithPopup(provider)
              .then(function(result) {
              }).catch(function(err) {
              });
          };

          const encodeHTML = function(s) {
            return s.replace(/</g, '&lt;').replace(/"/g, '&quot;').replace(/>/g, '&gt;');
          };

          const saveNewComment = function(comment) {
            if (!currentUser) {
              return;
            }
            let commentData = {
              user: currentUser.displayName,
              avatar: currentUser.photoURL,
              time: (new Date()).toISOString(),
              message: encodeHTML(comment)
            };
            database.ref(postCommentURL).push(commentData);
            document.getElementById("comment-content").value = "";
          };

          const submitComment = function(e) {
            let keyCode = e.which || e.keyCode;
            let ctrlCode = e.ctrlKey || e.metaKey;
            if (keyCode === 13 && ctrlCode) {
              let comment = document.getElementById("comment-content").value;
              saveNewComment(comment);
            }
          };

          const filterURLinComment = function(comment) {
            return comment.replace(/(https?:\/\/(?:www\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\.[^\s]{2,}|www\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\.[^\s]{2,}|https?:\/\/(?:www\.|(?!www))[a-zA-Z0-9]\.[^\s]{2,}|www\.[a-zA-Z0-9]\.[^\s]{2,})/g, "<a target='_blank' rel='noopener noreferrer' href='$1'>$1</a>");
          };

          const addNewComment = function(user, avatar, time, comment) {
            let commentFiltered = encodeHTML(comment);
            commentFiltered = filterURLinComment(commentFiltered);
            let d = new Date(time);
            let commentTime = d.toLocaleTimeString() + ' ' + d.toLocaleDateString();
            let html = '<div class="avatar">' +
              '   <img src="' + avatar + '" width="32" height="32"/>' +
              ' </div>' +
              '<div class="comment">' +
              '  <div class="metadata"><b>' + user + '</b> lúc <span>' + commentTime + '</span></div>' +
              '  <div class="content">' + commentFiltered
              '  </div>' +
              '</div>';
            let li = document.createElement('li');
            li.innerHTML = html;
            document.getElementById("comment-list").append(li);
          };

          let database = firebase.database();
          let posts = database.ref(postCommentURL).orderByChild('time');
          posts.on('child_added', function(data) {
            addNewComment(data.val().user, data.val().avatar, data.val().time, data.val().message);
          });
        </script>
    </body>
</html>
